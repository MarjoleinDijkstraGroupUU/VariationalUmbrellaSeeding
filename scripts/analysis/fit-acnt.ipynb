{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234299d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa6b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import chi2\n",
    "\n",
    "from natsort import natsorted\n",
    "import os\n",
    "import warnings\n",
    "from scipy.special import logsumexp\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba35ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import acnt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29ac064a",
   "metadata": {},
   "source": [
    "# 1. Define fitting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb958023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot local biased probability distribution and local free-energy profile\n",
    "def plot_local_free_energy(G_bias_, target_size, params, N, p, plot_g0, dU, color0, i):\n",
    "    plot_mask = (G_bias_ - G_bias_.min()) < 4 #10.0\n",
    "    pmin = 0\n",
    "    plot_mask = (p > pmin)\n",
    "    G1 = acnt.r_pol(target_size, *params) -np.log(p[plot_mask]) + np.log(p.max()) + plot_g0\n",
    "    plot_mask = ((G1 - G1.min()) < 4)\n",
    "    plt.plot(N[p>pmin][plot_mask], G1[plot_mask] - dU[p>pmin][plot_mask], c=f'C{color0+i}', ls=':', zorder=2e9)\n",
    "    plt.plot(N[p>pmin][plot_mask], G1[plot_mask], c=f'C{color0+i}', ls='--')\n",
    "\n",
    "\n",
    "# compute likelihood for given set of params\n",
    "# and make some plots of the barrier if requested\n",
    "def compute_negative_loglikelihood(params, windows, Ns, p_s, plot_g0=None, color0=0):\n",
    "    logL = 0 # total loglikelihood\n",
    "\n",
    "    # iterate over simulation data\n",
    "    for i, (target_size, bias_width) in enumerate(windows):\n",
    "        if target_size == 0:\n",
    "            continue\n",
    "\n",
    "        # read samples\n",
    "        nmin = 5\n",
    "        mask = (Ns[i] > nmin)\n",
    "        N = Ns[i][mask] # nucleus size\n",
    "        p = p_s[i][mask] # nucleus size distribution\n",
    "\n",
    "        # compute local likelihood\n",
    "        bias_width_ = bias_width if target_size > 0 else np.inf\n",
    "        dU = 0.5 * (N - target_size)**2 / bias_width_**2 # bias potential\n",
    "        G = acnt.r_pol(N, *params) # local free-energy according to aCNT parameters\n",
    "        G_bias = G + dU\n",
    "\n",
    "        # compute normalization\n",
    "        if target_size != 0:\n",
    "            N_ = np.arange(max(nmin, target_size-10*bias_width), target_size+10*bias_width)\n",
    "        else:\n",
    "            N_ = np.arange(nmin, 30)\n",
    "        G_ = acnt.r_pol(N_, *params)\n",
    "        dU_ = 0.5 * (N_ - target_size)**2 / bias_width_**2\n",
    "        G_bias_ = G_ + dU_\n",
    "        logZ = logsumexp(-G_bias_) # log of normalization constant\n",
    "        G_bias += logZ\n",
    "\n",
    "        # add local loglikelihood to total loglikelihood\n",
    "        logL -= np.sum(-p * G_bias)\n",
    "\n",
    "        # If requested, plot local biased probability distribution and local free-energy profile\n",
    "        if plot_g0 is not None:\n",
    "            plot_local_free_energy(G_bias_, target_size, params, N, p, plot_g0, dU, color0, i)\n",
    "\n",
    "    return logL\n",
    "\n",
    "\n",
    "# Fit the constant additive parameter 'g_0' of the aCNT\n",
    "def fit_g0(params, windows, Ns, p_s, plot=True):\n",
    "    # get unbiased part\n",
    "    for i, (target_size, bias_width) in enumerate(windows):\n",
    "        if target_size == 0:\n",
    "            # get unbiased nucleus size distribution\n",
    "            mask = (p_s[i] > 0)\n",
    "            Nu = Ns[i][mask]\n",
    "            p_ = p_s[i][mask]\n",
    "\n",
    "            # convert to free-energy\n",
    "            Gu = -np.log(p_).values\n",
    "\n",
    "            # subtract log(total number of particles)\n",
    "            Ntot = p_[0]\n",
    "            for k in Nu:\n",
    "                Ntot += k * p_[k]\n",
    "            Gu -= -np.log(Ntot)\n",
    "            break\n",
    "\n",
    "    # fit g0 by glueing unbiased free-energy Gu to acnt fit\n",
    "    iNG0 = np.argmin(np.abs(Gu - 10.0))\n",
    "    N0 = Nu[iNG0]\n",
    "    g0 = Gu[iNG0] - acnt.r_pol(N0, *params)\n",
    "    mask = (Gu < 11)\n",
    "    if plot:\n",
    "        plt.plot(Nu[mask], Gu[mask], c='k', zorder=1e8, label=r'$-\\log p(n)$', lw=1)\n",
    "\n",
    "    return g0\n",
    "\n",
    "\n",
    "# Fit the aCNT parameters to observations\n",
    "def fit_acnt_mle(windows, Ns, p_s, plot=True):\n",
    "\n",
    "    # maximize loglikehood to optimize aCNT params\n",
    "    bound = 100\n",
    "    params = minimize(\n",
    "        compute_negative_loglikelihood,\n",
    "        args=(windows, Ns, p_s),\n",
    "        x0=(0.5, 0.0,), bounds=((-bound, bound), (-bound, bound),)\n",
    "        ).x\n",
    "    \n",
    "    # fit the constant additive parameter 'g_0' of the aCNT\n",
    "    g0 = fit_g0(params, windows, Ns, p_s, plot)\n",
    "    params = np.append(params, g0)\n",
    "\n",
    "    # compute critical nucleus size and barrier height from aCNT parameters\n",
    "    sol = minimize(acnt.r_pol_g0_max, args=tuple(params), x0=100)\n",
    "    Nc, Gc = round(sol.x[0]), -sol.fun\n",
    "\n",
    "    return Nc, Gc, params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1bd4ea",
   "metadata": {},
   "source": [
    "# 2. Get simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ade755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define thermodynamic quantities and simulation model\n",
    "def get_model(model, y):\n",
    "    if model == 'wca':\n",
    "        p = 12.0 # pressure\n",
    "        bonds = y # number of solidlike bonds as solid-fluid criterion\n",
    "        d0 = f'../../results/hmc/{model}/p{p}_{bonds}-bonds' # base directory of data\n",
    "        dmu = 0.41 # supersaturation\n",
    "        rho_s = 0.844 # density of solid phase\n",
    "        kT = 1.0 \n",
    "        sigma = 1.0 # diameter of a particle\n",
    "    else:\n",
    "        T = y # temperature\n",
    "        kB = 1.380648520000e-23  # Boltzmann's constant [m^2 kg s^-2 K^-1]\n",
    "        Nav = 6.02214090000e23\n",
    "\n",
    "        if model == 'mW':\n",
    "            kT = kB*T               # J\n",
    "            kT_ = kB*T*Nav / 4184   # kcal/mol\n",
    "            sigma = 2.3925          # diameter of a particle, in Angstrom\n",
    "            rho_s = 0.985e3/(18.0153e-3)*Nav*(sigma*1e-10)**3        # (/sigma^3)\n",
    "            dmu = -0.1553/kT_ / 34.6 *(T-274.6) # supersaturation in kT, taken from \"Homogeneous ice nucleation evaluated for several water models (2014)\"\n",
    "            d0 = f'../../results/hmc/{model}/T{T}'\n",
    "        elif model == 'tip4pice':\n",
    "            kT = kB*T               # J\n",
    "            kT_ = kB*T*Nav / 4184   # kcal/mol\n",
    "            dmu = 0.146/kT_ /(270-230)*(270 - T) #(\"On the time required\") kT\n",
    "            sigma = 3.1668e-10          # diameter of a particle, in meter\n",
    "            rho_s = 0.9112e3/(18.0154e-3)*Nav*sigma**3 # \"Lattice mold 2022\" (/sigma^3)\n",
    "            gamma = 1e-3*(30.044 - 0.27477*(270 - T))/kT*sigma**2 # (kT/sigma^2) \"On the time required\"\n",
    "            d0 = f'../../results/hmc/{model}/T{T}' # base directory of data\n",
    "\n",
    "    return d0, dmu\n",
    "\n",
    "\n",
    "# read logs of nucleus size over time\n",
    "def get_data():\n",
    "    Ns = [] # nucleus size\n",
    "    p_s = [] # nucleus size distribution\n",
    "    windows = [] # target sizes and bias widths\n",
    "\n",
    "    # compute autocorrelation time of a correlated timeseries\n",
    "    def compute_acf(y):\n",
    "        def autocorrelation(data, lag):\n",
    "            n = len(data)\n",
    "            mean = np.mean(data)\n",
    "            numerator = np.sum((data[:n-lag] - mean) * (data[lag:] - mean))\n",
    "            denominator = n * np.var(data)\n",
    "            acf = numerator / denominator\n",
    "            return acf\n",
    "\n",
    "        # Calculate the autocorrelation for a range of lags\n",
    "        max_lag = len(y)//2\n",
    "        lags = np.arange(1, max_lag, 10)\n",
    "        autocorrelation_values = np.array([autocorrelation(y, round(lag)) for lag in lags])\n",
    "        threshold = (1/np.e)\n",
    "        auto_correlation_time = lags[np.argmin(np.abs(autocorrelation_values-threshold))]\n",
    "        \n",
    "        return auto_correlation_time\n",
    "\n",
    "    # iterate over target sizes\n",
    "    for n_ in natsorted(os.listdir(d0)):\n",
    "        if not n_.startswith('n'):\n",
    "            continue\n",
    "        n = round(float(n_[1:])) # target size\n",
    "        df = None # empty pandas dataframe\n",
    "\n",
    "        # find right subdirectory for data\n",
    "        integrator_ = integrator if n > 0 else 'npt'\n",
    "        if n == 0:\n",
    "            d2_ = [f for f in os.listdir(f'{d0}/{n_}') if f.startswith(integrator_) and f.endswith('False')][0]\n",
    "        else:\n",
    "            d2_ = [f for f in os.listdir(f'{d0}/{n_}') if f.startswith(integrator_)][0]\n",
    "        d2 = f'{d0}/{n_}/{d2_}'\n",
    "        \n",
    "        # iterate over all simulations for one target size\n",
    "        for i in os.listdir(d2):\n",
    "\n",
    "            # find last nucleus size histogram\n",
    "            d1 = f'{d0}/{n_}/{d2_}/{i}'\n",
    "            hists = [f for f in os.listdir(d1) if f.startswith('nucleus_size')]\n",
    "            files = natsorted(hists)\n",
    "\n",
    "            # find bias width\n",
    "            if n != 0:\n",
    "                args = pd.read_csv(f'{d1}/args.dat', delim_whitespace=True, header=None, names=['key', 'value'], comment='#')\n",
    "                bias_width = float(args[args['key'] == 'bias_width']['value'])\n",
    "            else:\n",
    "                bias_width = np.inf\n",
    "\n",
    "            # read nucleus size distribution\n",
    "            nucleus_size_hist_path = f'{d1}/nucleus_size_hist_processed.csv'\n",
    "            if os.path.exists(nucleus_size_hist_path):\n",
    "                df1 = pd.read_csv(nucleus_size_hist_path,)\n",
    "            elif n == 0:\n",
    "                df1 = pd.read_csv(f'{d1}/{files[-1]}',)\n",
    "                files = files[len(files)//2:]\n",
    "                if len(files) > 1:\n",
    "                    df0 = pd.read_csv(f'{d1}/{files[0]}',)\n",
    "                    df1['count'] -= df0['count']\n",
    "            else:\n",
    "                # read nucleus size timeseries\n",
    "                thermo = pd.read_csv(f'{d1}/thermo.dat', delim_whitespace=True, comment='#')\n",
    "\n",
    "                # estimate correlation length and subsample\n",
    "                observable = thermo['nucleus_size'].values\n",
    "                observable = observable[round(len(thermo)/10):]\n",
    "                skip = round(compute_acf(observable))\n",
    "                thermo = thermo[len(thermo)//10::skip]\n",
    "                            \n",
    "                # obtain nucleus size distribution\n",
    "                nmin = round(max(0, n-20*bias_width))\n",
    "                nmax = round(n+20*bias_width)\n",
    "                bins = np.arange(nmin, nmax+2) - 0.5\n",
    "                N = np.arange(nmin, nmax+1)\n",
    "                p, _ = np.histogram(thermo['nucleus_size'], bins=bins)\n",
    "                df1 = pd.DataFrame(np.array([N, p]).T, columns=['nucleus_size', 'count'])\n",
    "\n",
    "            # accumulate\n",
    "            df1.to_csv(nucleus_size_hist_path, index=False)\n",
    "            if df is None:\n",
    "                df = df1.__deepcopy__()\n",
    "            else:\n",
    "                df['count'] += df1['count']\n",
    "\n",
    "        # gather data to return\n",
    "        if df is not None:\n",
    "            windows.append((n, bias_width,))\n",
    "            Ns.append(df['nucleus_size'])\n",
    "            p_s.append(df['count'])\n",
    "\n",
    "    return windows, Ns, p_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228f1ca6",
   "metadata": {},
   "source": [
    "# Confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b27c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate confidence intervals for the nucleus size and barrier height\n",
    "def get_confidence_interval(params, windows, Ns, p_s):\n",
    "    # compute loglikelihood of most likely parameters\n",
    "    logL0 = compute_negative_loglikelihood(params[:-1], windows, Ns, p_s, plot_g0=None)\n",
    "\n",
    "    # compute loglikelihood test threshold\n",
    "    coverage = 0.95 # 95% confidence interval\n",
    "    df = 2 # number of parameters to estimate\n",
    "    dlogL0 = chi2.ppf(coverage, df=df) / 2\n",
    "    Lrel0 = np.exp(-dlogL0)\n",
    "\n",
    "    # compute loglikelihood relative to most likely parameters\n",
    "    def get_dL(params_):\n",
    "        logL = compute_negative_loglikelihood(params_, windows, Ns, p_s, plot_g0=None)\n",
    "        return logL0 - logL\n",
    "\n",
    "    # compute critical nucleus size and barrier height\n",
    "    def get_Nc_G(params_):\n",
    "        # refit g0\n",
    "        g0 = fit_g0(params_, windows, Ns, p_s, plot=False)\n",
    "        params_.append(g0)\n",
    "\n",
    "        # compute Nc and dG\n",
    "        sol = minimize(acnt.r_pol_g0_max, args=tuple(params_), x0=100)\n",
    "        Nc, dG = round(sol.x[0]), -sol.fun\n",
    "\n",
    "        return Nc, dG, params_\n",
    "\n",
    "    # plot Nc and G versus relative likelihood\n",
    "    def plot_intermediate(params_, plot='G'):\n",
    "        Nc, G, params_ = get_Nc_G(params_)\n",
    "        dlogL = get_dL(params_[:-1])\n",
    "        Lrel = np.exp(dlogL)\n",
    "\n",
    "        if Lrel < 1:\n",
    "            # plot Nc and G versus relative likelihood\n",
    "            if plot == 'G':\n",
    "                plt.scatter(G, Lrel, c='C0')\n",
    "            else:\n",
    "                plt.scatter(Nc, Lrel, c='C0')\n",
    "\n",
    "            # print Nc and G if relative likelihood is close to boundary\n",
    "            if np.abs(Lrel-Lrel0)<5e-3:\n",
    "                print(Nc, G, Lrel)\n",
    "\n",
    "    # vary aCNT parameters and compute relative likelihood\n",
    "    for dg2 in np.linspace(-0.2, 0.2, num=200):\n",
    "        for dg1 in np.linspace(-0.2, 0.2, num=3):\n",
    "            params_ = [params[0]+dg2, params[1]+dg1]\n",
    "            plot_intermediate(params_, plot='G')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ea160b",
   "metadata": {},
   "source": [
    "# 3. Fit barriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e54d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, ys = 'wca', [6,7,8]\n",
    "# model, ys = 'mW', [215.1, 225.0, 235.0],\n",
    "model, ys = 'tip4pice', [230.0]\n",
    "plot = True\n",
    "confidence = False\n",
    "\n",
    "for integrator in ['npt','nve'][:]:\n",
    "    for y in ys[:]:\n",
    "        print(y)\n",
    "        # get data\n",
    "        d0, acnt.dmu = get_model(model, y)\n",
    "        windows, Ns, p_s = get_data()\n",
    "\n",
    "        # fit aCNT\n",
    "        Nc, Gc, params = fit_acnt_mle(windows, Ns, p_s, plot=plot)\n",
    "\n",
    "        print(f'Supersaturation (|Δμ|):  {acnt.dmu:.3f} kT')\n",
    "        print('aCNT fit parameters (g2, g1, g0):', params)\n",
    "        print('Integrator:', integrator)\n",
    "        print('Barrier height:', f'{Gc:.1f} kT')\n",
    "        print('Critical nucleus size (n*):', Nc)\n",
    "        print('n* |Δμ| / 2:', f'{0.5*Nc*acnt.dmu:.1f} kT')\n",
    "        # print(acnt.dmu, integrator, y, params, f'{Gc:.1f} {0.5*Nc*acnt.dmu:.1f} {Nc}')\n",
    "\n",
    "        if plot:\n",
    "            # plot local free-energy profiles\n",
    "            compute_negative_loglikelihood(params[:-1], windows, Ns, p_s, plot_g0=params[-1])\n",
    "\n",
    "            # plot fitted total free-energy profile\n",
    "            N = np.arange(0, 1.2*Nc)\n",
    "            G = acnt.r_pol_g0(N, *params)\n",
    "            N0_ = np.argmin(np.abs(G-10.0))\n",
    "            mask = (N > N0_)\n",
    "            plt.plot(N[mask], G[mask], c='k', label=r'$\\beta \\Delta G_{\\mathrm{aCNT}} (\\gamma,\\alpha,\\Delta)$')\n",
    "\n",
    "            # savefig\n",
    "            plt.xlabel(r'$n$')\n",
    "            plt.ylabel(r'$\\beta \\Delta G$')\n",
    "            plt.xlim(0,)\n",
    "            plt.ylim(0,)\n",
    "            plt.legend(loc='lower right')\n",
    "            # plt.savefig(f'../../results/figs/{model}-{y}-barrier.png', dpi=300)\n",
    "            plt.show()\n",
    "\n",
    "        if confidence:\n",
    "            get_confidence_interval(params, windows, Ns, p_s,)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb07a001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ovito-freud')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8318bc5daa99ea02fe4bdd6b46a2ee286718f226f8e35bb0cd6777ac2269cf90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
